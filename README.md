# interpretable-ml-notes
阅读iml书籍的实战操练，汇集了常见的机器学习可解释包及用法。

## 内容概要
* 对机器学习模型进行解释的重要性，什么场景需要解释，解释的要点有哪些.
* 自带解释性的方法：线性回归，广义线性模型.
* robust regression 以及简单的模型诊断
* 自带解释性的方法：rulefit（自动包含交互作用）.
* 复杂模型解释：
  * 特征层面：PDP, ICE, ALE; feature importance; 交互作用.
  * 案例层面：LIME, shapley value, breakdown.
* 常见机器学习包的模型解释方法
  * iml, jtools, DALEX, breakDown, lime
  * 对h2o模型的封装。
  
## 主要参考资料
* interpretable machine learning (https://christophm.github.io/interpretable-ml-book/)
* 上述各个包文档.